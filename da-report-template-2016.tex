\documentclass[12pt]{article}

\usepackage{fullpage}
\usepackage{multicol,multirow}
\usepackage{tabularx}
\usepackage{ulem}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}

\begin{document}

\section*{Лабораторная работа №\,1 по курсу дискрeтного анализа: сортировка за линейное время}

Выполнил студент группы 08-201 МАИ \textit{Трофимов Максим}.

\subsection*{Условие}

Кратко описывается задача: 
\begin{enumerate}
\item Требуется разработать программу, осуществляющую ввод пар 
«ключ-значение», их упорядочивание по возрастанию ключа указанным 
алгоритмом сортировки за линейное время и вывод отсортированной 
последовательности.


\item Вариант 9-1.
Алгоритм Bucket sort. 
Ключ принимает значение от -100.0 до 100.0.
Значение это строка длины 64 символа.
	
\end{enumerate}

\subsection*{Метод решения}

Программа считывает из стандартного входного потока пары ключ-значение.
потом сортирует их с помощью Bucket sort:
создаётся дополнительный массив векторов (кармашкев).
Потом в эти кармашки "раскидываются" элементы сортируемого вектора.
Затем все эти кормашки сортируются с помощью Insretion sortю
Кормашки обратно восстанавлюваются до обычного линейного массива в исходный массив, 
который сортировался изначально.
Кормен Дискретный анализ. 
Видео на Youtube.

\subsection*{Описание программы}

Data - структура. По сути пара из ключа и значания.
Tvector - класс для создания и  работы с динамическим массивом типа Data.
BucketSort - Функция, принимающая на вход вектор по ссылке и сортирует его.

\subsection*{Дневник отладки}

11.10.19 - проверил программу с помощью valgrind - забы чистить память за "кармашками"
12.10.19 - программа выделяла слишком много памяти, т.е. кармашки сразу были размером 
с сам сортируемый массив. Т.е. n^2 доп. памяти- стал увеличивать размер кармашка в процессе их наполнения.
16.10.19 - исправлял стиль кода.

\subsection*{Тест производительности}

 время   || количество пар 
 секунды || млн шт.
 ========||===============
  0.361  ||   1
  0.673  ||   2
  1.087  ||   3
  1.409  ||   4
  1.744  ||   5
  2.197  ||   6
  2.625  ||   7 
  2.873  ||   8
  3.304  ||   9
  3.650  ||   10
  4.492  ||   11
 27.475  ||   12
 53.036	 ||   13
 ========||===============

Среднее отношение количества входных данных (млн) к времени работы сортировки (сек) ~2.7 
и примерно соответствует всем тестам, кроме последних тестов. Там, скорее всего много времени
тратиться на выделение таких больших массивов.

\subsection*{Выводы}

Данный алгоритм лучше всего применять в том случае, если входные данные примерно
равномерно распределены на каком-то определённом отрезке (на отрезке от минимального 
и максимального значения ключа/элемента). Весьма эффективно сортирует входные данные 
такого рода.

Данный алгоритм весьма прост в написании, если правильно его понимать. 
Т.е. один цикл на раскидку по кармашкам, один на сортировку каждого кармашка и 
ещё один цикл на восстановление массива.

\end{document}

